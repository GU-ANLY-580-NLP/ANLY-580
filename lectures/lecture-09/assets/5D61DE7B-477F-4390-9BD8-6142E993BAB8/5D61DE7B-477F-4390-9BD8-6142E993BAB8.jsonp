local_slide( {"name":"5D61DE7B-477F-4390-9BD8-6142E993BAB8","json":{"assets":{"286AAD78695274F03F24D4F078F4A2D3":{"type":"texture","index":0,"assetRequest":{"type":"slide","state":"contents","slide":"none"},"url":{"native":"assets\/5D61DE7B-477F-4390-9BD8-6142E993BAB8.pdf"},"width":1920,"height":1080},"6DEEB52F0FC9BB15790F694D9703480A":{"type":"texture","index":1,"assetRequest":{"type":"slide","state":"contents","slide":"none"},"url":{"native":"assets\/5D61DE7B-477F-4390-9BD8-6142E993BAB8.pdf"},"width":1920,"height":1080}},"events":[{"effects":[{"beginTime":0,"baseLayer":{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"objectID":"0","layers":[{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,-0.00035007912466775983,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"layers":[{"animations":[],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"6DEEB52F0FC9BB15790F694D9703480A"},{"animations":[{"additive":false,"timeOffset":0,"beginTime":0,"from":{"scalar":false},"repeatCount":0,"fillMode":"both","duration":0.01,"autoreverses":false,"property":"hidden","to":{"scalar":true},"removedOnCompletion":false}],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"286AAD78695274F03F24D4F078F4A2D3"}]}]},"effects":[],"duration":0.01,"type":"transition","attributes":{"direction":0},"name":"none","objectID":"0"}],"automaticPlay":false,"hyperlinks":[],"accessibility":[{"text":"GPT (2018-present)","targetRectangle":{"y":4,"x":40,"width":613.05999999999983,"height":84}},{"text":"“ ” except 175B parameters","targetRectangle":{"y":726.71781826019287,"x":185.57440185546875,"width":201.00800000000004,"height":21.839999675750732}},{"text":"LM pretraining on Common Crawl dataset (~1T words)","targetRectangle":{"y":770.71781826019287,"x":185.57440185546875,"width":400.24000000000001,"height":21.839999675750732}},{"text":"equation.pdf","targetRectangle":{"y":824.770263671875,"x":747.4267578125,"width":107.64982672082738,"height":20.543819999999982}},{"text":"GPT 2","targetRectangle":{"y":178.40278518199921,"x":73.241073608398438,"width":45.903999999999996,"height":21.839999675750732}},{"text":"equation.pdf","targetRectangle":{"y":671.510009765625,"x":764.4505615234375,"width":97.602216404676483,"height":15.179999095201538}},{"text":"equation.pdf","targetRectangle":{"y":771.95281982421875,"x":760.6798095703125,"width":72.473067631359072,"height":20.548000000000002}},{"text":"Figure taken from Bloem, 2020","targetRectangle":{"y":914.32609450817108,"x":1343.7618875732423,"width":231.77599999999984,"height":21.839999675750732}},{"text":"equation.pdf","targetRectangle":{"y":362.900390625,"x":758.7562255859375,"width":71.967063341787593,"height":20.371998785734149}},{"text":"equation.pdf","targetRectangle":{"y":719.13543701171875,"x":757.15478515625,"width":74.885023167863551,"height":20.547998775243741}},{"text":"Brown et al., Language Models are Few-Shot Learners (2020)","targetRectangle":{"y":905.89243972301483,"x":76.368263244628906,"width":450.84800000000007,"height":21.839999675750732}},{"text":"pasted-image.pdf","targetRectangle":{"y":164.79498291015625,"x":1275.4398193359375,"width":359.58834838867188,"height":750.4100341796875}},{"text":"GPT 3","targetRectangle":{"y":587.54319655895233,"x":73.241073608398438,"width":46.496000000000009,"height":21.839999675750732}},{"text":"equation.pdf","targetRectangle":{"y":310.08297729492188,"x":758.23126220703125,"width":75.017027631359042,"height":20.372000000000014}},{"text":"equation.pdf","targetRectangle":{"y":415.71780395507812,"x":746.91485595703125,"width":107.64982672082738,"height":20.543819999999982}},{"text":"equation.pdf","targetRectangle":{"y":262.28158569335938,"x":766.93865966796875,"width":75.602217715978668,"height":15.355999084711073}},{"text":"Autoregressive model (i.e., causal, only backwards connections)","targetRectangle":{"y":223.64558362960815,"x":187.06240844726562,"width":478.97599999999989,"height":21.839999675750732}},{"text":"Uses BytePair tokens","targetRectangle":{"y":267.64558362960815,"x":187.06240844726562,"width":154.89599999999996,"height":21.839999675750732}},{"text":"Trained on WebText dataset (~8M high quality web pages)","targetRectangle":{"y":311.64558362960815,"x":187.06240844726562,"width":430.22399999999993,"height":21.839999675750732}},{"text":"Positional embeddings","targetRectangle":{"y":355.64558362960815,"x":187.06240844726562,"width":170.6400000000001,"height":21.839999675750732}},{"text":"1.5B parameters","targetRectangle":{"y":399.64558362960815,"x":187.06240844726562,"width":119.20000000000005,"height":21.839999675750732}},{"text":"￼","targetRectangle":{"y":1038.7800302505493,"x":1890.8349829391809,"width":20.394000000000005,"height":26}},{"text":"Brown et al., Language Models are Unsupervised Multitask Learners (2018)","targetRectangle":{"y":494.88835036754608,"x":74.368263244628906,"width":550.65600000000018,"height":21.839999675750732}}],"baseLayer":{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"objectID":"0","layers":[{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,-0.00035007912466775983,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"layers":[{"animations":[],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"286AAD78695274F03F24D4F078F4A2D3"}]}]}}]}} )